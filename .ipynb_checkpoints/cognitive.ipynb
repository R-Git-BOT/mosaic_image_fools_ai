{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "available-sending",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"KEY\": \"YOUR_KEY\",\n",
    "    \"ENDPOINT\": \"YOUR_ENDPOINT\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "caring-recycling",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-vision-computervision in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from azure-cognitiveservices-vision-computervision) (1.1.28)\n",
      "Requirement already satisfied: msrest>=0.5.0 in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from azure-cognitiveservices-vision-computervision) (0.6.21)\n",
      "Requirement already satisfied: requests~=2.16 in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2020.4.5.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.3.1)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (0.6.1)\n",
      "Requirement already satisfied: six in c:\\users\\silve\\appdata\\roaming\\python\\python38\\site-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.14.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.25.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (8.2.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from opencv-python) (1.22.3)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\silve\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from opencv-contrib-python) (1.22.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade azure-cognitiveservices-vision-computervision\n",
    "!pip3 install pillow\n",
    "!pip3 install opencv-python\n",
    "!pip3 install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "hydraulic-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "import pathlib\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "# コピペ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('secret.json') as f:\n",
    "    secret = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = secret['KEY']\n",
    "ENDPOINT = secret['ENDPOINT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "computervision_client = ComputerVisionClient(ENDPOINT, CognitiveServicesCredentials(KEY))\n",
    "# endpoint と key　があればAPIを使うことが出来る コピペ https://docs.microsoft.com/ja-jp/azure/cognitive-services/computer-vision/quickstarts-sdk/client-library?tabs=visual-studio&pivots=programming-language-python#authenticate-the-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read API を呼び出す\n",
    "\n",
    "# 画像のURLから呼び出し\n",
    "# remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\"\n",
    "remote_image_url = \"https://pbs.twimg.com/media/Dr3eZhtX4AAvAu8.jpg\"\n",
    "# remote_image_url = \"https://cdn.extra.ie/wp-content/uploads/2019/10/15104422/tank5.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-terminology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Describe an image - remote =====\n",
      "Description of remote image: \n",
      "'a group of men posing for a picture' with confidence 61.35%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Describe an Image - remote\n",
    "This example describes the contents of an image with the confidence score.\n",
    "'''\n",
    "print(\"===== Describe an image - remote =====\")\n",
    "# Call API\n",
    "description_results = computervision_client.describe_image(remote_image_url )\n",
    "\n",
    "# Get the captions (descriptions) from the response, with confidence level\n",
    "print(\"Description of remote image: \")\n",
    "if (len(description_results.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_results.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
    "        #json 形式でデータが帰ってくる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-harvey",
   "metadata": {},
   "source": [
    "## 画像カテゴリの取得\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-weapon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Categorize an image - remote =====\n",
      "Categories from remote image: \n",
      "'people_crowd' with confidence 43.75%\n",
      "'people_group' with confidence 44.53%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Categorize an Image - remote\n",
    "This example extracts (general) categories from a remote image with a confidence score.\n",
    "'''\n",
    "print(\"===== Categorize an image - remote =====\")\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [\"categories\"]\n",
    "# Call API with URL and features\n",
    "categorize_results_remote = computervision_client.analyze_image(remote_image_url , remote_image_features)\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(categorize_results_remote.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in categorize_results_remote.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-grant",
   "metadata": {},
   "source": [
    "## 画像タグの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-metabolism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Tag an image - remote =====\n",
      "Tags in the remote image: \n",
      "'person' with confidence 99.35%\n",
      "'clothing' with confidence 97.00%\n",
      "'human face' with confidence 94.92%\n",
      "'footwear' with confidence 94.53%\n",
      "'thigh' with confidence 93.97%\n",
      "'outdoor' with confidence 93.64%\n",
      "'muscle' with confidence 92.20%\n",
      "'chest' with confidence 90.50%\n",
      "'man' with confidence 90.25%\n",
      "'barechested' with confidence 89.87%\n",
      "'sunglasses' with confidence 88.80%\n",
      "'abdomen' with confidence 88.31%\n",
      "'stomach' with confidence 88.26%\n",
      "'shorts' with confidence 87.29%\n",
      "'undergarment' with confidence 85.99%\n",
      "'human beard' with confidence 85.06%\n",
      "'flesh' with confidence 84.65%\n",
      "'smile' with confidence 84.63%\n",
      "'navel' with confidence 84.54%\n",
      "'ground' with confidence 76.30%\n",
      "'people' with confidence 74.49%\n",
      "'group' with confidence 72.74%\n",
      "'posing' with confidence 63.02%\n",
      "'wearing' with confidence 55.14%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Tag an Image - remote\n",
    "This example returns a tag (key word) for each thing in the image.\n",
    "'''\n",
    "print(\"===== Tag an image - remote =====\")\n",
    "# Call API with remote image\n",
    "tags_result_remote = computervision_client.tag_image(remote_image_url)\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-elizabeth",
   "metadata": {},
   "source": [
    "## 物体を検出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-camel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Objects - remote =====\n",
      "Detecting objects in remote image:\n",
      "shirts\n",
      "object at location 213, 365, 85, 208\n",
      "Jeans\n",
      "object at location 218, 402, 179, 384\n",
      "Skateboard\n",
      "object at location 238, 417, 298, 416\n",
      "person\n",
      "object at location 116, 419, 60, 386\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Detect Objects - remote\n",
    "This example detects different kinds of objects with bounding boxes in a remote image.\n",
    "'''\n",
    "print(\"===== Detect Objects - remote =====\")\n",
    "# Get URL image with different objects\n",
    "remote_image_url_objects = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg\"\n",
    "# Call API with URL\n",
    "detect_objects_results_remote = computervision_client.detect_objects(remote_image_url_objects)\n",
    "\n",
    "# Print detected objects results with bounding boxes\n",
    "print(\"Detecting objects in remote image:\")\n",
    "if len(detect_objects_results_remote.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_remote.objects:\n",
    "        print(object.object_property)\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20877d43",
   "metadata": {},
   "source": [
    "# えっちな画像か検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c53d010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Detect Adult or Racy Content - remote =====\n",
      "Analyzing remote image for adult or racy content ... \n",
      "Is adult content: False with confidence 35.82\n",
      "Has racy content: True with confidence 96.03\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Detect Adult or Racy Content - remote\n",
    "This example detects adult or racy content in a remote image, then prints the adult/racy score.\n",
    "The score is ranged 0.0 - 1.0 with smaller numbers indicating negative results.\n",
    "'''\n",
    "print(\"===== Detect Adult or Racy Content - remote =====\")\n",
    "# Select the visual feature(s) you want\n",
    "remote_image_features = [\"adult\"]\n",
    "# Call API with URL and features\n",
    "detect_adult_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
    "\n",
    "# Print results with adult/racy score\n",
    "print(\"Analyzing remote image for adult or racy content ... \")\n",
    "print(\"Is adult content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_adult_content, detect_adult_results_remote.adult.adult_score * 100))\n",
    "print(\"Has racy content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_racy_content, detect_adult_results_remote.adult.racy_score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-hydrogen",
   "metadata": {},
   "source": [
    "## ローカルファイルに対応させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "serious-reviewer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample03_mosaic.jpg\n",
      "===== Detect Objects - local =====\n",
      "Detecting objects in local image:\n",
      "person\n",
      "object at location 567, 861, 219, 669\n",
      "person\n",
      "object at location 756, 1070, 307, 823\n",
      "person\n",
      "object at location 35, 457, 622, 1547\n",
      "person\n",
      "object at location 598, 1064, 537, 1550\n",
      "Analyzing remote image for adult or racy content ... \n",
      "Is adult content: False with confidence 49.38\n",
      "Has racy content: True with confidence 97.12\n",
      "Has gore content: False with confidence 0.44\n"
     ]
    }
   ],
   "source": [
    "local_image_path = './../sample03.jpg'\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "\n",
    "local_image_cv = cv2.imread(local_image_path)\n",
    "\n",
    "def mosaic(src, ratio=0.1):\n",
    "    small = cv2.resize(src, None, fx=ratio, fy=ratio, interpolation=cv2.INTER_NEAREST)\n",
    "    return cv2.resize(small, src.shape[:2][::-1], interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "dst = mosaic(local_image_cv, 0.5)\n",
    "mosaic_stem = pathlib.Path(local_image_path).stem\n",
    "mosaic_suffix = pathlib.Path(local_image_path).suffix\n",
    "\n",
    "mosaic_image_path = mosaic_stem + '_mosaic' +mosaic_suffix\n",
    "print(mosaic_image_path)\n",
    "\n",
    "cv2.imwrite(mosaic_image_path, dst)\n",
    "mosaic_image = open(mosaic_image_path, \"rb\")\n",
    "\n",
    "print(\"===== Detect Objects - local =====\")\n",
    "detect_objects_results = computervision_client.detect_objects_in_stream(local_image)\n",
    "\n",
    "print(\"Detecting objects in local image:\")\n",
    "if len(detect_objects_results.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results.objects:\n",
    "        print(object.object_property)\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))\n",
    "\n",
    "\n",
    "remote_image_features = [\"adult\"]\n",
    "# Call API with URL and features\n",
    "detect_adult_results_remote = computervision_client.analyze_image_in_stream(mosaic_image, remote_image_features)\n",
    "\n",
    "# Print results with adult/racy score\n",
    "print(\"Analyzing remote image for adult or racy content ... \")\n",
    "print(\"Is adult content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_adult_content, detect_adult_results_remote.adult.adult_score * 100))\n",
    "print(\"Has racy content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_racy_content, detect_adult_results_remote.adult.racy_score * 100))\n",
    "print(\"Has gore content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_gory_content, detect_adult_results_remote.adult.gore_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71b7f922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing image for adult or racy, gore content ... \n",
      "Is adult content: False with confidence 44.97\n",
      "Has racy content: True with confidence 96.37\n",
      "Has gore content: False with confidence 0.53\n",
      "Analyzing mosaic image for adult or racy, gore content ... \n",
      "Is adult content: False with confidence 49.38\n",
      "Has racy content: True with confidence 97.12\n",
      "Has gore content: False with confidence 0.44\n"
     ]
    }
   ],
   "source": [
    "local_image_path = './../sample03.jpg'\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "\n",
    "local_image_cv = cv2.imread(local_image_path)\n",
    "\n",
    "def mosaic(src, ratio=0.1):\n",
    "    small = cv2.resize(src, None, fx=ratio, fy=ratio, interpolation=cv2.INTER_NEAREST)\n",
    "    return cv2.resize(small, src.shape[:2][::-1], interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "dst = mosaic(local_image_cv, 0.5)\n",
    "mosaic_stem = pathlib.Path(local_image_path).stem\n",
    "mosaic_suffix = pathlib.Path(local_image_path).suffix\n",
    "\n",
    "mosaic_image_path = mosaic_stem + '_mosaic' +mosaic_suffix\n",
    "\n",
    "cv2.imwrite(mosaic_image_path, dst)\n",
    "mosaic_image = open(mosaic_image_path, \"rb\")\n",
    "\n",
    "remote_image_features = [\"adult\"]\n",
    "# Call API with URL and features\n",
    "detect_adult_results_remote = computervision_client.analyze_image_in_stream(local_image, remote_image_features)\n",
    "detect_adult_results_remote_mosaic = computervision_client.analyze_image_in_stream(mosaic_image, remote_image_features)\n",
    "\n",
    "# Print results with adult/racy score\n",
    "print(\"Analyzing image for adult or racy, gore content ... \")\n",
    "print(\"Is adult content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_adult_content, detect_adult_results_remote.adult.adult_score * 100))\n",
    "print(\"Has racy content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_racy_content, detect_adult_results_remote.adult.racy_score * 100))\n",
    "print(\"Has gore content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_gory_content, detect_adult_results_remote.adult.gore_score * 100))\n",
    "\n",
    "print(\"Analyzing mosaic image for adult or racy, gore content ... \")\n",
    "print(\"Is adult content: {} with confidence {:.2f}\".format(detect_adult_results_remote_mosaic.adult.is_adult_content, detect_adult_results_remote_mosaic.adult.adult_score * 100))\n",
    "print(\"Has racy content: {} with confidence {:.2f}\".format(detect_adult_results_remote_mosaic.adult.is_racy_content, detect_adult_results_remote_mosaic.adult.racy_score * 100))\n",
    "print(\"Has gore content: {} with confidence {:.2f}\".format(detect_adult_results_remote_mosaic.adult.is_gory_content, detect_adult_results_remote_mosaic.adult.gore_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_image_path = './../sample03.jpg'\n",
    "local_image = open(local_image_path, \"rb\")\n",
    "\n",
    "local_image_cv = cv2.imread(local_image_path)\n",
    "\n",
    "def mosaic(src, ratio=0.1):\n",
    "    small = cv2.resize(src, None, fx=ratio, fy=ratio, interpolation=cv2.INTER_NEAREST)\n",
    "    return cv2.resize(small, src.shape[:2][::-1], interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "dst = mosaic(local_image_cv, 0.5)\n",
    "mosaic_stem = pathlib.Path(local_image_path).stem\n",
    "mosaic_suffix = pathlib.Path(local_image_path).suffix\n",
    "\n",
    "mosaic_image_path = mosaic_stem + '_mosaic' +mosaic_suffix\n",
    "\n",
    "cv2.imwrite(mosaic_image_path, dst)\n",
    "mosaic_image = open(mosaic_image_path, \"rb\")\n",
    "\n",
    "remote_image_features = [\"adult\"]\n",
    "# Call API with URL and features\n",
    "detect_adult_results_remote = computervision_client.analyze_image_in_stream(local_image, remote_image_features)\n",
    "detect_adult_results_remote_mosaic = computervision_client.analyze_image_in_stream(mosaic_image, remote_image_features)\n",
    "\n",
    "def detect_arc(imagepath):\n",
    "    local_image = open(imagepath, \"rb\")\n",
    "    # remote_image_features = [\"adult\"]\n",
    "    detect_adult_results_remote = computervision_client.analyze_image_in_stream(local_image, [\"adult\"])\n",
    "\n",
    "    return [detect_adult_results_remote.adult.adult_score * 100, detect_adult_results_remote.racy.racy_score * 100, detect_adult_results_remote.gore.gore_score * 100]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "later-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(filepath):\n",
    "    local_image = open(filepath, \"rb\")\n",
    "\n",
    "    tags_result = computervision_client.tag_image_in_stream(local_image)\n",
    "    tags = tags_result.tags\n",
    "    tags_name = []\n",
    "    for tag in tags:\n",
    "        tags_name.append(tag.name)\n",
    "        \n",
    "    return tags_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "difficult-overhead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tableware',\n",
       " 'food',\n",
       " 'baked goods',\n",
       " 'plate',\n",
       " 'drink',\n",
       " 'coffee cup',\n",
       " 'dishware',\n",
       " 'saucer',\n",
       " 'snack',\n",
       " 'serveware',\n",
       " 'meal',\n",
       " 'mug',\n",
       " 'tea',\n",
       " 'fast food',\n",
       " 'breakfast',\n",
       " 'fork',\n",
       " 'kitchen utensil',\n",
       " 'dish',\n",
       " 'brunch',\n",
       " 'platter',\n",
       " 'dessert',\n",
       " 'cup',\n",
       " 'coffee',\n",
       " 'indoor',\n",
       " 'sitting',\n",
       " 'table']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = './../sample01.jpg'\n",
    "get_tags(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(filepath):\n",
    "    local_image = open(filepath, \"rb\")\n",
    "\n",
    "    detect_objects_results = computervision_client.detect_objects_in_stream(local_image)\n",
    "    objects = detect_objects_results.objects\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'sample01.jpg'\n",
    "objects = detect_objects(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-bacon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects[0].rectangle.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
